{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pharmaceutical-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import official.nlp.bert.tokenization as tokenization\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_raw_input(text, label, test_size):\n",
    "    \n",
    "    x = text\n",
    "    y = label\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, stratify=y)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    label_encoder.fit(y)\n",
    "    encoded_y_train = label_encoder.transform(y_train)\n",
    "    encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "    dummy_y_train = np_utils.to_categorical(encoded_y_train)\n",
    "    dummy_y_test = np_utils.to_categorical(encoded_y_test)\n",
    "    \n",
    "    return x_train, x_test, dummy_y_train, dummy_y_test\n",
    "\n",
    "def pull_bert(bert_type):\n",
    "    \n",
    "    loaded_model = hub.load(bert_type)\n",
    "    bert_layer = hub.KerasLayer(loaded_model, trainable = False)\n",
    "\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "    tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "    \n",
    "    return bert_layer, tokenizer\n",
    "\n",
    "\n",
    "def encode_names(n, tokenizer):\n",
    "    tokens = list(tokenizer.tokenize(n))\n",
    "    tokens.append('[SEP]')\n",
    "    return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "\n",
    "def get_max_lengths(text, tokenizer):\n",
    "    \n",
    "    tweets = tf.ragged.constant([\n",
    "        encode_names(n, tokenizer) for n in text\n",
    "    ])\n",
    "\n",
    "    tweet_lens = [len(tweet) for tweet in tweets]\n",
    "    max_seq_len = int(max(tweet_lens))\n",
    "    \n",
    "    return max_seq_len\n",
    "\n",
    "\n",
    "def get_lengths(text, tokenizer):\n",
    "    \n",
    "    tweets = tf.ragged.constant([\n",
    "        encode_names(n, tokenizer) for n in text\n",
    "    ])\n",
    "\n",
    "    tweet_lens = [len(tweet) for tweet in tweets]\n",
    "    \n",
    "    return tweet_lens\n",
    "\n",
    "\n",
    "def bert_encode(string_list, tokenizer, max_seq_length):\n",
    "    num_examples = len(string_list)\n",
    "    \n",
    "    string_tokens = tf.ragged.constant([\n",
    "        encode_names(n, tokenizer) for n in np.array(string_list)\n",
    "    ])\n",
    "    \n",
    "    cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*string_tokens.shape[0]\n",
    "    input_word_ids = tf.concat([cls, string_tokens], axis=1)\n",
    "    \n",
    "    input_mask = tf.ones_like(input_word_ids).to_tensor(shape=(None, max_seq_length))\n",
    "    \n",
    "    type_cls = tf.zeros_like(cls)\n",
    "    type_tokens = tf.ones_like(string_tokens)\n",
    "    input_type_ids = tf.concat([type_cls, type_tokens], axis=1).to_tensor(shape=(None, max_seq_length))\n",
    "    \n",
    "    inputs = {\n",
    "        'input_word_ids': input_word_ids.to_tensor(shape=(None, max_seq_length)),\n",
    "        'input_mask': input_mask,\n",
    "        'input_type_ids': input_type_ids\n",
    "    }\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-column",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
